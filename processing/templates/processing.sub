# ==============================================================================
# processing.sub - HTCondor submit file for MC processing chain
# ==============================================================================
# This template is used by dag_generator.py to submit processing jobs.
# Runs the full chain: Shower -> Mix -> GEN-SIM -> RAW -> RECO -> MiniAOD -> Ntuple
#
# Required variables (set via DAGMan VARS):
#   campaign   - Campaign name (e.g., JJP_DPS1)
#   job_id     - Job identifier
#   inputs     - Comma-separated pool:index pairs
#   modes      - Comma-separated shower modes (normal|phi)
#   analysis   - Analysis type (JJP or JUP)
#   n_sources  - Number of input sources
# ==============================================================================

Universe = vanilla

# Executable and arguments
Executable = /afs/cern.ch/user/x/xcheng/condor/MC_Production_DAG/T2_CN_Beijing/processing/run_chain.sh
Arguments = --inputs $(inputs) --modes $(modes) --analysis $(analysis) --campaign $(campaign) --job-id $(job_id)

# Input files to transfer (self-contained sandbox)
Transfer_Input_Files = /afs/cern.ch/user/x/xcheng/condor/MC_Production_DAG/T2_CN_Beijing/processing/run_chain.sh, \
					   /afs/cern.ch/user/x/xcheng/condor/MC_Production_DAG/T2_CN_Beijing/processing/pythia_shower, \
					   /afs/cern.ch/user/x/xcheng/condor/MC_Production_DAG/T2_CN_Beijing/common

# Output handling
Should_Transfer_Files = YES
WhenToTransferOutput = ON_EXIT

# Log files
Output = log/proc_$(campaign)_$(job_id)_$(Cluster)_$(Process).stdout
Error = log/proc_$(campaign)_$(job_id)_$(Cluster)_$(Process).stderr
Log = log/proc_$(campaign)_$(job_id)_$(Cluster)_$(Process).log

# Resource requirements
# Full chain is very resource intensive
request_cpus = 8
request_memory = 20GB
request_disk = 50GB

# Target T2_CN_Beijing site
+DESIRED_Sites = "T2_CN_Beijing"

# Run in CMSSW-compatible container
+SingularityImage = "/cvmfs/unpacked.cern.ch/registry.hub.docker.com/cmssw/el8:x86_64"

# Environment setup
# Environment setup - use actual user ID for proxy path
Environment = "HOME=/afs/cern.ch/user/x/xcheng X509_USER_PROXY=/afs/cern.ch/user/x/xcheng/x509up_u180107"

# Retry configuration
MaxRetries = 2
OnExitHold = (ExitCode != 0)
OnExitHoldReason = "Job exited with non-zero status"
OnExitHoldSubCode = 1

# Periodic release of held jobs
PeriodicRelease = (JobRunCount < 2) && (HoldReasonCode == 3)

# No host OS requirement - we run inside Singularity el8 container
# Container runs fine on AlmaLinux9 hosts

# Queue single job
Queue 1
